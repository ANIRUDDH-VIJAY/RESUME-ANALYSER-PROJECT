{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aebdb58-3573-4116-bbed-9b4ac15ef11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: D:\\RESUME-ANALYSER-PROJECT\n",
      "--- Loading master_resumes.jsonl ---\n",
      "master_resumes.jsonl loaded successfully!\n",
      "\n",
      "First 5 rows of master_resumes_df:\n",
      "                                       personal_info  \\\n",
      "0  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "1  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "2  {'name': 'Not Provided', 'email': 'Not Provide...   \n",
      "3  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "4  {'name': '', 'email': '', 'phone': '', 'locati...   \n",
      "\n",
      "                                          experience  \\\n",
      "0  [{'company': 'Fresher', 'company_info': {'indu...   \n",
      "1  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
      "2  [{'company': 'Parkar Consulting and Labs', 'co...   \n",
      "3  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
      "4  [{'company': 'Atos Syntel', 'company_info': {'...   \n",
      "\n",
      "                                           education  \\\n",
      "0  [{'degree': {'level': 'ME', 'field': 'Computer...   \n",
      "1  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
      "2  [{'degree': {'level': 'B.E.', 'field': 'Not Pr...   \n",
      "3  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
      "4  [{'degree': {'level': 'Bachelor of Engineering...   \n",
      "\n",
      "                                              skills  \\\n",
      "0  {'technical': {'programming_languages': [{'nam...   \n",
      "1  {'technical': {'project_management': [{'name':...   \n",
      "2  {'technical': {'programming_languages': [{'nam...   \n",
      "3  {'technical': {'project_management': [{'name':...   \n",
      "4  {'technical': {'programming_languages': [{'nam...   \n",
      "\n",
      "                                            projects  \\\n",
      "0  [{'name': 'Unknown', 'description': 'Unknown',...   \n",
      "1  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
      "2  [{'name': 'FPGA Implementation', 'description'...   \n",
      "3  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
      "4                                                 []   \n",
      "\n",
      "                                      certifications  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                                      \n",
      "4  {\"name\": \"ESD Program\", \"issuer\": \"Zensar Tech...   \n",
      "\n",
      "                                        achievements  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  [Treasurer in IEEE student branch at JSCOE, Pu...   \n",
      "\n",
      "                                           workshops publications  \\\n",
      "0                                                NaN          NaN   \n",
      "1                                                NaN          NaN   \n",
      "2                                                NaN          NaN   \n",
      "3                                                NaN          NaN   \n",
      "4  [{'name': 'Medical IoT', 'issuer': 'IEEE Stand...          NaN   \n",
      "\n",
      "  teaching_experience internships  \n",
      "0                 NaN         NaN  \n",
      "1                 NaN         NaN  \n",
      "2                 NaN         NaN  \n",
      "3                 NaN         NaN  \n",
      "4                 NaN         NaN  \n",
      "\n",
      "Info for master_resumes_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4817 entries, 0 to 4816\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   personal_info        4816 non-null   object\n",
      " 1   experience           4817 non-null   object\n",
      " 2   education            4817 non-null   object\n",
      " 3   skills               4817 non-null   object\n",
      " 4   projects             4806 non-null   object\n",
      " 5   certifications       4817 non-null   object\n",
      " 6   achievements         4 non-null      object\n",
      " 7   workshops            4 non-null      object\n",
      " 8   publications         3 non-null      object\n",
      " 9   teaching_experience  1 non-null      object\n",
      " 10  internships          2 non-null      object\n",
      "dtypes: object(11)\n",
      "memory usage: 414.1+ KB\n",
      "\n",
      "Sample of 'skills' column from master_resumes_df (first 3 entries):\n",
      "Resume 1 Skills: {'technical': {'programming_languages': [{'name': 'Python', 'level': 'intermediate'}, {'name': 'C++', 'level': 'intermediate'}, {'name': 'C', 'level': 'intermediate'}], 'frameworks': [{'name': 'Tensorflow', 'level': 'intermediate'}, {'name': 'Numpy', 'level': 'intermediate'}], 'databases': [{'name': 'MySQL', 'level': 'intermediate'}], 'cloud': [{'name': 'Unknown', 'level': 'Unknown'}]}, 'languages': [{'name': 'Unknown', 'level': 'Unknown'}]}\n",
      "Resume 2 Skills: {'technical': {'project_management': [{'name': 'Project Execution', 'level': 'expert'}, {'name': 'Quality Management', 'level': 'advanced'}, {'name': 'Budget Monitoring', 'level': 'advanced'}], 'automation': [{'name': 'PLC Programming', 'level': 'advanced'}, {'name': 'SCADA Systems', 'level': 'advanced'}], 'software_tools': [{'name': 'SAP', 'level': 'intermediate'}, {'name': 'Microsoft Visio', 'level': 'intermediate'}]}, 'languages': [{'name': 'English', 'level': 'fluent'}]}\n",
      "Resume 3 Skills: {'technical': {'programming_languages': [{'name': 'C', 'level': 'Basic'}, {'name': 'SQL', 'level': 'Basic'}, {'name': 'PL/SQL', 'level': 'Basic'}, {'name': 'JAVA', 'level': 'Basic'}, {'name': 'JAVAEE', 'level': 'Basic'}, {'name': 'Javascript', 'level': 'Basic'}, {'name': 'HTML', 'level': 'Basic'}, {'name': 'CSS', 'level': 'Basic'}, {'name': 'jquery', 'level': 'Basic'}, {'name': 'mysql', 'level': 'Basic'}, {'name': 'Spring', 'level': 'Basic'}, {'name': 'Hibernate', 'level': 'Basic'}, {'name': 'Python', 'level': 'Basic'}], 'frameworks': [{'name': 'Not Provided', 'level': 'Not Provided'}], 'databases': [{'name': 'Not Provided', 'level': 'Not Provided'}], 'cloud': [{'name': 'AWS', 'level': 'Not Provided'}]}, 'languages': [{'name': 'English', 'level': 'Not Provided'}]}\n",
      "\n",
      "\n",
      "--- Loading training_data.csv ---\n",
      "training_data.csv loaded successfully!\n",
      "\n",
      "First 5 rows of training_data_df:\n",
      "  company_name                                    job_description  \\\n",
      "0       Google  minimum qualifications\\nbachelors degree or eq...   \n",
      "1        Apple  description\\nas an asc you will be highly infl...   \n",
      "2      Netflix  its an amazing time to be joining netflix as w...   \n",
      "3  Robert Half  description\\n\\nweb designers looking to expand...   \n",
      "4    TrackFive  at trackfive weve got big goals were on a miss...   \n",
      "\n",
      "                              position_title  description_length  \\\n",
      "0                           Sales Specialist                2727   \n",
      "1                 Apple Solutions Consultant                 828   \n",
      "2  Licensing Coordinator - Consumer Products                3205   \n",
      "3                               Web Designer                2489   \n",
      "4                              Web Developer                3167   \n",
      "\n",
      "                                      model_response  \n",
      "0   {\\n  \"Core Responsibilities\": \"Responsible fo...  \n",
      "1   {\\n  \"Core Responsibilities\": \"as an asc you ...  \n",
      "2   {\\n  \"Core Responsibilities\": \"Help drive bus...  \n",
      "3   {\\n  \"Core Responsibilities\": \"Designing webs...  \n",
      "4   {\\n  \"Core Responsibilities\": \"Build and layo...  \n",
      "\n",
      "Info for training_data_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 853 entries, 0 to 852\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   company_name        853 non-null    object\n",
      " 1   job_description     853 non-null    object\n",
      " 2   position_title      853 non-null    object\n",
      " 3   description_length  853 non-null    int64 \n",
      " 4   model_response      853 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 33.4+ KB\n",
      "\n",
      "Sample of 'model_response' column from training_data_df (first 3 entries, parsed JSON):\n",
      "JD 1 Model Response: {\n",
      "  \"Core Responsibilities\": \"Responsible for expanding Google Workspace product adoption across an assigned territory. Build relationships with customers to understand needs and provide Google Workspace solutions. Partner with account teams to construct solutions and grow business for Google Workspace.\",\n",
      "  \"Required Skills\": \"Bachelor's degree or equivalent experience. Experience managing enterprise SaaS accounts and sales cycles.\",\n",
      "  \"Educational Requirements\": \"Bachelor's degree or equivalent experience.\",\n",
      "  \"Experience Level\": \"Experience managing enterprise SaaS accounts and sales cycles.\",\n",
      "  \"Preferred Qualifications\": \"Experience building strategic partnerships with enterprise customers. Ability to work through a reseller ecosystem. Excellent communication and strategic thinking skills.\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "JD 2 Model Response: {\n",
      "  \"Core Responsibilities\": \"as an asc you will be highly influential in growing mind and market share of apple products while building longterm relationships with those who share your passion customer experiences are driven through you and your partner team growing in an ever changing and challenging environment you strive for perfection whether its maintaining visual merchandising or helping to grow and develop your partner team\",\n",
      "  \"Required Skills\": \"a passion to help people understand how apple products can enrich their livesexcellent communication skills allowing you to be as comfortable in front of a small group as you are speaking with individuals years preferred working in a dynamic sales andor results driven environment as well as proven success developing customer loyaltyability to encourage a partner team and grow apple business\",\n",
      "  \"Educational Requirements\": \"N/A\",\n",
      "  \"Experience Level\": \"years preferred\",\n",
      "  \"Preferred Qualifications\": \"N/A\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "JD 3 Model Response: {\n",
      "  \"Core Responsibilities\": \"Help drive business by supporting licensing managers on tasks related to category management, facilitating information between stakeholders, maintaining communication plans. Coordinate with internal teams to share brand and marketing updates with partners. Maintain and update title strategies and licensing plans. Collaborate with partners on product launches. Assist with licensing recaps, meetings, and agreements.\",\n",
      "  \"Required Skills\": \"2+ years experience in preferably outbound licensing. Understanding of category manufacturing and sales cycles for toys/food/beverage preferred. Experience with entertainment/lifestyle brands. Self-starter, proactive, flexible. Thrives under pressure. Superb organizational and multitasking skills. Excellent communication skills.\",\n",
      "  \"Educational Requirements\": \"N/A\",\n",
      "  \"Experience Level\": \"2+ years experience in preferably outbound licensing\",\n",
      "  \"Preferred Qualifications\": \"Understanding of category manufacturing and sales cycles for toys and/or food and beverage preferred. Experience working with reputable entertainment and/or lifestyle brands.\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "\n",
      "\n",
      "--- Loading roles-based-on-skills.csv ---\n",
      "roles-based-on-skills.csv loaded successfully!\n",
      "\n",
      "First 5 rows of roles_skills_df after renaming:\n",
      "   Unnamed: 0           Job Role  \\\n",
      "0           0  Software Engineer   \n",
      "1           1  Software Engineer   \n",
      "2           2  Software Engineer   \n",
      "3           3  Software Engineer   \n",
      "4           4  Software Engineer   \n",
      "\n",
      "                                                 ALL  \n",
      "0  Java Android Development PHP HTML C Cascading ...  \n",
      "1                                                ...  \n",
      "2  JavaScript Reactjs MySQL ObjectOriented Progra...  \n",
      "3  Java JavaScript PHP HTML Cascading Style Sheet...  \n",
      "4  Java Android Development C Communication HTML ...  \n",
      "\n",
      "Info for roles_skills_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4576 entries, 0 to 4575\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4576 non-null   int64 \n",
      " 1   Job Role    4576 non-null   object\n",
      " 2   ALL         4576 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 107.4+ KB\n",
      "\n",
      "Unique Job Roles and their counts:\n",
      "Job Role\n",
      "Software Engineer            667\n",
      "Quality Assurance            502\n",
      "Network Engineer             491\n",
      "Business Analyst             490\n",
      "Machine Learning Engineer    486\n",
      "DevOps                       468\n",
      "Data Science                 418\n",
      "Cyber Security               392\n",
      "Mobile App Developer         390\n",
      "Data Engineer                272\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Performing TF-IDF Vectorization ---\n",
      "Shape of TF-IDF matrix: (4576, 5000)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Splitting data into training and testing sets ---\n",
      "Training set size: 3660 samples\n",
      "Testing set size: 916 samples\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Logistic Regression Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANIRUDDH\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Accuracy: 0.8908\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         Business Analyst       0.93      0.96      0.94        98\n",
      "           Cyber Security       0.97      0.91      0.94        78\n",
      "            Data Engineer       0.78      0.57      0.66        54\n",
      "             Data Science       0.86      0.83      0.85        84\n",
      "                   DevOps       0.93      0.90      0.92        94\n",
      "Machine Learning Engineer       0.80      0.82      0.81        97\n",
      "     Mobile App Developer       0.96      0.95      0.95        78\n",
      "         Network Engineer       0.88      0.93      0.91        98\n",
      "        Quality Assurance       0.98      0.95      0.96       101\n",
      "        Software Engineer       0.82      0.93      0.87       134\n",
      "\n",
      "                 accuracy                           0.89       916\n",
      "                macro avg       0.89      0.88      0.88       916\n",
      "             weighted avg       0.89      0.89      0.89       916\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Job Role Classification Pipeline Complete ---\n",
      "You now have a trained model that can predict job roles based on skills!\n",
      "\n",
      "--- Saving Trained Model and Vectorizer ---\n",
      "TF-IDF Vectorizer saved to: backend/models\\tfidf_vectorizer.joblib\n",
      "Job Role Classifier Model saved to: backend/models\\job_role_classifier_model.joblib\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- CRITICAL: Change working directory to the project root ---\n",
    "# This ensures all subsequent relative paths are correct.\n",
    "# Assumes the notebook is in 'notebooks/' and the project root is one level up.\n",
    "try:\n",
    "    current_dir = os.getcwd()\n",
    "    if os.path.basename(current_dir) == 'notebooks':\n",
    "        os.chdir(os.path.dirname(current_dir))\n",
    "        print(f\"Changed working directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Current working directory: {current_dir}\")\n",
    "        print(\"Assuming it's already the project root or a parent directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error changing directory: {e}\")\n",
    "    exit() # Exit if we can't set the correct working directory\n",
    "\n",
    "\n",
    "# --- 1. Load and Inspect master_resumes.jsonl ---\n",
    "print(\"--- Loading master_resumes.jsonl ---\")\n",
    "resumes_data = []\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    with open('data/master_resumes.jsonl', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            resumes_data.append(json.loads(line))\n",
    "    master_resumes_df = pd.DataFrame(resumes_data)\n",
    "    print(\"master_resumes.jsonl loaded successfully!\")\n",
    "    print(\"\\nFirst 5 rows of master_resumes_df:\")\n",
    "    print(master_resumes_df.head())\n",
    "    print(\"\\nInfo for master_resumes_df:\")\n",
    "    master_resumes_df.info()\n",
    "    print(\"\\nSample of 'skills' column from master_resumes_df (first 3 entries):\")\n",
    "    for i, skills in enumerate(master_resumes_df['skills'].head(3)):\n",
    "        print(f\"Resume {i+1} Skills: {skills}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/master_resumes.jsonl' not found. Ensure it's in the 'data' folder at the project root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading master_resumes.jsonl: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 2. Load and Inspect training_data.csv ---\n",
    "print(\"--- Loading training_data.csv ---\")\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    training_data_df = pd.read_csv('data/training_data.csv')\n",
    "    print(\"training_data.csv loaded successfully!\")\n",
    "    print(\"\\nFirst 5 rows of training_data_df:\")\n",
    "    print(training_data_df.head())\n",
    "    print(\"\\nInfo for training_data_df:\")\n",
    "    training_data_df.info()\n",
    "    \n",
    "    print(\"\\nSample of 'model_response' column from training_data_df (first 3 entries, parsed JSON):\")\n",
    "    for i, json_str in enumerate(training_data_df['model_response'].head(3)):\n",
    "        try:\n",
    "            parsed_json = json.loads(json_str)\n",
    "            print(f\"JD {i+1} Model Response: {json.dumps(parsed_json, indent=2)}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JD {i+1} Model Response (Error parsing JSON): {json_str}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/training_data.csv' not found. Ensure it's in the 'data' folder at the project root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading training_data.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. Load and Inspect roles-based-on-skills.csv ---\n",
    "print(\"--- Loading roles-based-on-skills.csv ---\")\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    roles_skills_df = pd.read_csv('data/roles-based-on-skills.csv')\n",
    "    print(\"roles-based-on-skills.csv loaded successfully!\")\n",
    "    \n",
    "    # Correct column name for Job Role for consistency\n",
    "    roles_skills_df.rename(columns={'Target': 'Job Role'}, inplace=True)\n",
    "\n",
    "    print(\"\\nFirst 5 rows of roles_skills_df after renaming:\")\n",
    "    print(roles_skills_df.head())\n",
    "    print(\"\\nInfo for roles_skills_df:\")\n",
    "    roles_skills_df.info()\n",
    "    print(\"\\nUnique Job Roles and their counts:\")\n",
    "    print(roles_skills_df['Job Role'].value_counts())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/roles-based-on-skills.csv' not found. Ensure it's in the 'data' folder at the project root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading roles-based-on-skills.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Prepare Data for Job Role Classification ---\n",
    "X = roles_skills_df['ALL']  # The column containing all skills as a string\n",
    "y = roles_skills_df['Job Role'] # The target job role\n",
    "\n",
    "# 1. Feature Engineering: Convert text skills to numerical features using TF-IDF\n",
    "print(\"\\n--- Performing TF-IDF Vectorization ---\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limit features to top 5000 for efficiency\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "print(f\"Shape of TF-IDF matrix: {X_tfidf.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 2. Split Data into Training and Testing Sets\n",
    "print(\"\\n--- Splitting data into training and testing sets ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Model Training: Logistic Regression Classifier\n",
    "print(\"\\n--- Training Logistic Regression Model ---\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear') # Increased max_iter for convergence\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n--- Job Role Classification Pipeline Complete ---\")\n",
    "print(\"You now have a trained model that can predict job roles based on skills!\")\n",
    "\n",
    "\n",
    "# --- Save Trained Model and TF-IDF Vectorizer ---\n",
    "print(\"\\n--- Saving Trained Model and Vectorizer ---\")\n",
    "# Define paths to save the model and vectorizer within the backend/models folder\n",
    "# These paths are relative to the project root, which is the current working directory\n",
    "# if you launched Jupyter from there.\n",
    "models_dir = 'backend/models'\n",
    "os.makedirs(models_dir, exist_ok=True) # This creates the directory if it doesn't exist\n",
    "\n",
    "vectorizer_path = os.path.join(models_dir, 'tfidf_vectorizer.joblib')\n",
    "model_path = os.path.join(models_dir, 'job_role_classifier_model.joblib')\n",
    "\n",
    "# Save the TF-IDF Vectorizer\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "print(f\"TF-IDF Vectorizer saved to: {vectorizer_path}\")\n",
    "\n",
    "# Save the trained Logistic Regression Model\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Job Role Classifier Model saved to: {model_path}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3ae84-8b09-4a27-b991-33bddb2c0a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfdf7e4-d6f2-43db-9817-66bc514fd16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: D:\\RESUME-ANALYSER-PROJECT\n",
      "--- Loading master_resumes.jsonl ---\n",
      "master_resumes.jsonl loaded successfully!\n",
      "\n",
      "First 5 rows of master_resumes_df:\n",
      "                                       personal_info  \\\n",
      "0  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "1  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "2  {'name': 'Not Provided', 'email': 'Not Provide...   \n",
      "3  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "4  {'name': '', 'email': '', 'phone': '', 'locati...   \n",
      "\n",
      "                                          experience  \\\n",
      "0  [{'company': 'Fresher', 'company_info': {'indu...   \n",
      "1  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
      "2  [{'company': 'Parkar Consulting and Labs', 'co...   \n",
      "3  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
      "4  [{'company': 'Atos Syntel', 'company_info': {'...   \n",
      "\n",
      "                                           education  \\\n",
      "0  [{'degree': {'level': 'ME', 'field': 'Computer...   \n",
      "1  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
      "2  [{'degree': {'level': 'B.E.', 'field': 'Not Pr...   \n",
      "3  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
      "4  [{'degree': {'level': 'Bachelor of Engineering...   \n",
      "\n",
      "                                              skills  \\\n",
      "0  {'technical': {'programming_languages': [{'nam...   \n",
      "1  {'technical': {'project_management': [{'name':...   \n",
      "2  {'technical': {'programming_languages': [{'nam...   \n",
      "3  {'technical': {'project_management': [{'name':...   \n",
      "4  {'technical': {'programming_languages': [{'nam...   \n",
      "\n",
      "                                            projects  \\\n",
      "0  [{'name': 'Unknown', 'description': 'Unknown',...   \n",
      "1  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
      "2  [{'name': 'FPGA Implementation', 'description'...   \n",
      "3  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
      "4                                                 []   \n",
      "\n",
      "                                      certifications  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                                      \n",
      "4  {\"name\": \"ESD Program\", \"issuer\": \"Zensar Tech...   \n",
      "\n",
      "                                        achievements  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  [Treasurer in IEEE student branch at JSCOE, Pu...   \n",
      "\n",
      "                                           workshops publications  \\\n",
      "0                                                NaN          NaN   \n",
      "1                                                NaN          NaN   \n",
      "2                                                NaN          NaN   \n",
      "3                                                NaN          NaN   \n",
      "4  [{'name': 'Medical IoT', 'issuer': 'IEEE Stand...          NaN   \n",
      "\n",
      "  teaching_experience internships  \n",
      "0                 NaN         NaN  \n",
      "1                 NaN         NaN  \n",
      "2                 NaN         NaN  \n",
      "3                 NaN         NaN  \n",
      "4                 NaN         NaN  \n",
      "\n",
      "Info for master_resumes_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4817 entries, 0 to 4816\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   personal_info        4816 non-null   object\n",
      " 1   experience           4817 non-null   object\n",
      " 2   education            4817 non-null   object\n",
      " 3   skills               4817 non-null   object\n",
      " 4   projects             4806 non-null   object\n",
      " 5   certifications       4817 non-null   object\n",
      " 6   achievements         4 non-null      object\n",
      " 7   workshops            4 non-null      object\n",
      " 8   publications         3 non-null      object\n",
      " 9   teaching_experience  1 non-null      object\n",
      " 10  internships          2 non-null      object\n",
      "dtypes: object(11)\n",
      "memory usage: 414.1+ KB\n",
      "\n",
      "Sample of 'skills' column from master_resumes_df (first 3 entries):\n",
      "Resume 1 Skills: {'technical': {'programming_languages': [{'name': 'Python', 'level': 'intermediate'}, {'name': 'C++', 'level': 'intermediate'}, {'name': 'C', 'level': 'intermediate'}], 'frameworks': [{'name': 'Tensorflow', 'level': 'intermediate'}, {'name': 'Numpy', 'level': 'intermediate'}], 'databases': [{'name': 'MySQL', 'level': 'intermediate'}], 'cloud': [{'name': 'Unknown', 'level': 'Unknown'}]}, 'languages': [{'name': 'Unknown', 'level': 'Unknown'}]}\n",
      "Resume 2 Skills: {'technical': {'project_management': [{'name': 'Project Execution', 'level': 'expert'}, {'name': 'Quality Management', 'level': 'advanced'}, {'name': 'Budget Monitoring', 'level': 'advanced'}], 'automation': [{'name': 'PLC Programming', 'level': 'advanced'}, {'name': 'SCADA Systems', 'level': 'advanced'}], 'software_tools': [{'name': 'SAP', 'level': 'intermediate'}, {'name': 'Microsoft Visio', 'level': 'intermediate'}]}, 'languages': [{'name': 'English', 'level': 'fluent'}]}\n",
      "Resume 3 Skills: {'technical': {'programming_languages': [{'name': 'C', 'level': 'Basic'}, {'name': 'SQL', 'level': 'Basic'}, {'name': 'PL/SQL', 'level': 'Basic'}, {'name': 'JAVA', 'level': 'Basic'}, {'name': 'JAVAEE', 'level': 'Basic'}, {'name': 'Javascript', 'level': 'Basic'}, {'name': 'HTML', 'level': 'Basic'}, {'name': 'CSS', 'level': 'Basic'}, {'name': 'jquery', 'level': 'Basic'}, {'name': 'mysql', 'level': 'Basic'}, {'name': 'Spring', 'level': 'Basic'}, {'name': 'Hibernate', 'level': 'Basic'}, {'name': 'Python', 'level': 'Basic'}], 'frameworks': [{'name': 'Not Provided', 'level': 'Not Provided'}], 'databases': [{'name': 'Not Provided', 'level': 'Not Provided'}], 'cloud': [{'name': 'AWS', 'level': 'Not Provided'}]}, 'languages': [{'name': 'English', 'level': 'Not Provided'}]}\n",
      "\n",
      "\n",
      "--- Loading training_data.csv ---\n",
      "training_data.csv loaded successfully!\n",
      "\n",
      "First 5 rows of training_data_df:\n",
      "  company_name                                    job_description  \\\n",
      "0       Google  minimum qualifications\\nbachelors degree or eq...   \n",
      "1        Apple  description\\nas an asc you will be highly infl...   \n",
      "2      Netflix  its an amazing time to be joining netflix as w...   \n",
      "3  Robert Half  description\\n\\nweb designers looking to expand...   \n",
      "4    TrackFive  at trackfive weve got big goals were on a miss...   \n",
      "\n",
      "                              position_title  description_length  \\\n",
      "0                           Sales Specialist                2727   \n",
      "1                 Apple Solutions Consultant                 828   \n",
      "2  Licensing Coordinator - Consumer Products                3205   \n",
      "3                               Web Designer                2489   \n",
      "4                              Web Developer                3167   \n",
      "\n",
      "                                      model_response  \n",
      "0   {\\n  \"Core Responsibilities\": \"Responsible fo...  \n",
      "1   {\\n  \"Core Responsibilities\": \"as an asc you ...  \n",
      "2   {\\n  \"Core Responsibilities\": \"Help drive bus...  \n",
      "3   {\\n  \"Core Responsibilities\": \"Designing webs...  \n",
      "4   {\\n  \"Core Responsibilities\": \"Build and layo...  \n",
      "\n",
      "Info for training_data_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 853 entries, 0 to 852\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   company_name        853 non-null    object\n",
      " 1   job_description     853 non-null    object\n",
      " 2   position_title      853 non-null    object\n",
      " 3   description_length  853 non-null    int64 \n",
      " 4   model_response      853 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 33.4+ KB\n",
      "\n",
      "Sample of 'model_response' column from training_data_df (first 3 entries, parsed JSON):\n",
      "JD 1 Model Response: {\n",
      "  \"Core Responsibilities\": \"Responsible for expanding Google Workspace product adoption across an assigned territory. Build relationships with customers to understand needs and provide Google Workspace solutions. Partner with account teams to construct solutions and grow business for Google Workspace.\",\n",
      "  \"Required Skills\": \"Bachelor's degree or equivalent experience. Experience managing enterprise SaaS accounts and sales cycles.\",\n",
      "  \"Educational Requirements\": \"Bachelor's degree or equivalent experience.\",\n",
      "  \"Experience Level\": \"Experience managing enterprise SaaS accounts and sales cycles.\",\n",
      "  \"Preferred Qualifications\": \"Experience building strategic partnerships with enterprise customers. Ability to work through a reseller ecosystem. Excellent communication and strategic thinking skills.\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "JD 2 Model Response: {\n",
      "  \"Core Responsibilities\": \"as an asc you will be highly influential in growing mind and market share of apple products while building longterm relationships with those who share your passion customer experiences are driven through you and your partner team growing in an ever changing and challenging environment you strive for perfection whether its maintaining visual merchandising or helping to grow and develop your partner team\",\n",
      "  \"Required Skills\": \"a passion to help people understand how apple products can enrich their livesexcellent communication skills allowing you to be as comfortable in front of a small group as you are speaking with individuals years preferred working in a dynamic sales andor results driven environment as well as proven success developing customer loyaltyability to encourage a partner team and grow apple business\",\n",
      "  \"Educational Requirements\": \"N/A\",\n",
      "  \"Experience Level\": \"years preferred\",\n",
      "  \"Preferred Qualifications\": \"N/A\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "JD 3 Model Response: {\n",
      "  \"Core Responsibilities\": \"Help drive business by supporting licensing managers on tasks related to category management, facilitating information between stakeholders, maintaining communication plans. Coordinate with internal teams to share brand and marketing updates with partners. Maintain and update title strategies and licensing plans. Collaborate with partners on product launches. Assist with licensing recaps, meetings, and agreements.\",\n",
      "  \"Required Skills\": \"2+ years experience in preferably outbound licensing. Understanding of category manufacturing and sales cycles for toys/food/beverage preferred. Experience with entertainment/lifestyle brands. Self-starter, proactive, flexible. Thrives under pressure. Superb organizational and multitasking skills. Excellent communication skills.\",\n",
      "  \"Educational Requirements\": \"N/A\",\n",
      "  \"Experience Level\": \"2+ years experience in preferably outbound licensing\",\n",
      "  \"Preferred Qualifications\": \"Understanding of category manufacturing and sales cycles for toys and/or food and beverage preferred. Experience working with reputable entertainment and/or lifestyle brands.\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "\n",
      "\n",
      "--- Loading roles-based-on-skills.csv ---\n",
      "roles-based-on-skills.csv loaded successfully!\n",
      "\n",
      "First 5 rows of roles_skills_df after renaming:\n",
      "   Unnamed: 0           Job Role  \\\n",
      "0           0  Software Engineer   \n",
      "1           1  Software Engineer   \n",
      "2           2  Software Engineer   \n",
      "3           3  Software Engineer   \n",
      "4           4  Software Engineer   \n",
      "\n",
      "                                                 ALL  \n",
      "0  Java Android Development PHP HTML C Cascading ...  \n",
      "1                                                ...  \n",
      "2  JavaScript Reactjs MySQL ObjectOriented Progra...  \n",
      "3  Java JavaScript PHP HTML Cascading Style Sheet...  \n",
      "4  Java Android Development C Communication HTML ...  \n",
      "\n",
      "Info for roles_skills_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4576 entries, 0 to 4575\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4576 non-null   int64 \n",
      " 1   Job Role    4576 non-null   object\n",
      " 2   ALL         4576 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 107.4+ KB\n",
      "\n",
      "Unique Job Roles and their counts:\n",
      "Job Role\n",
      "Software Engineer            667\n",
      "Quality Assurance            502\n",
      "Network Engineer             491\n",
      "Business Analyst             490\n",
      "Machine Learning Engineer    486\n",
      "DevOps                       468\n",
      "Data Science                 418\n",
      "Cyber Security               392\n",
      "Mobile App Developer         390\n",
      "Data Engineer                272\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Performing TF-IDF Vectorization ---\n",
      "Shape of TF-IDF matrix: (4576, 5000)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Splitting data into training and testing sets ---\n",
      "Training set size: 3660 samples\n",
      "Testing set size: 916 samples\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Logistic Regression Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANIRUDDH\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Accuracy: 0.8908\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         Business Analyst       0.93      0.96      0.94        98\n",
      "           Cyber Security       0.97      0.91      0.94        78\n",
      "            Data Engineer       0.78      0.57      0.66        54\n",
      "             Data Science       0.86      0.83      0.85        84\n",
      "                   DevOps       0.93      0.90      0.92        94\n",
      "Machine Learning Engineer       0.80      0.82      0.81        97\n",
      "     Mobile App Developer       0.96      0.95      0.95        78\n",
      "         Network Engineer       0.88      0.93      0.91        98\n",
      "        Quality Assurance       0.98      0.95      0.96       101\n",
      "        Software Engineer       0.82      0.93      0.87       134\n",
      "\n",
      "                 accuracy                           0.89       916\n",
      "                macro avg       0.89      0.88      0.88       916\n",
      "             weighted avg       0.89      0.89      0.89       916\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Job Role Classification Pipeline Complete ---\n",
      "You now have a trained model that can predict job roles based on skills!\n",
      "\n",
      "--- Saving Trained Model and Vectorizer ---\n",
      "TF-IDF Vectorizer saved to: backend\\models\\tfidf_vectorizer.joblib\n",
      "Job Role Classifier Model saved to: backend\\models\\job_role_classifier_model.joblib\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- CRITICAL: Change working directory to the project root ---\n",
    "# This approach is more robust for Jupyter Notebooks as it doesn't rely on __file__.\n",
    "# It assumes the notebook is in a 'notebooks/' subfolder directly under the project root.\n",
    "try:\n",
    "    current_working_dir = os.getcwd()\n",
    "    # Check if the current working directory ends with 'notebooks'\n",
    "    if current_working_dir.endswith(os.path.join('notebooks', '')) or current_working_dir.endswith('notebooks'):\n",
    "        # Go up one level to the project root\n",
    "        project_root_dir = os.path.abspath(os.path.join(current_working_dir, os.pardir))\n",
    "        os.chdir(project_root_dir)\n",
    "        print(f\"Changed working directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Current working directory: {current_working_dir}\")\n",
    "        print(\"Assuming it's already the project root or a parent directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error changing directory. Please ensure your notebook is run from within the 'notebooks' folder, or that the 'notebooks' folder is directly under your project root: {e}\")\n",
    "    exit() # Exit if we can't set the correct working directory\n",
    "\n",
    "\n",
    "# --- 1. Load and Inspect master_resumes.jsonl ---\n",
    "print(\"--- Loading master_resumes.jsonl ---\")\n",
    "resumes_data = []\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    with open(os.path.join('data', 'master_resumes.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            resumes_data.append(json.loads(line))\n",
    "    master_resumes_df = pd.DataFrame(resumes_data)\n",
    "    print(\"master_resumes.jsonl loaded successfully!\")\n",
    "    print(\"\\nFirst 5 rows of master_resumes_df:\")\n",
    "    print(master_resumes_df.head())\n",
    "    print(\"\\nInfo for master_resumes_df:\")\n",
    "    master_resumes_df.info()\n",
    "    print(\"\\nSample of 'skills' column from master_resumes_df (first 3 entries):\")\n",
    "    for i, skills in enumerate(master_resumes_df['skills'].head(3)):\n",
    "        print(f\"Resume {i+1} Skills: {skills}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/master_resumes.jsonl' not found. Ensure it's in the 'data' folder at the project root and Jupyter is launched from the root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading master_resumes.jsonl: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 2. Load and Inspect training_data.csv ---\n",
    "print(\"--- Loading training_data.csv ---\")\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    training_data_df = pd.read_csv(os.path.join('data', 'training_data.csv'))\n",
    "    print(\"training_data.csv loaded successfully!\")\n",
    "    print(\"\\nFirst 5 rows of training_data_df:\")\n",
    "    print(training_data_df.head())\n",
    "    print(\"\\nInfo for training_data_df:\")\n",
    "    training_data_df.info()\n",
    "    \n",
    "    print(\"\\nSample of 'model_response' column from training_data_df (first 3 entries, parsed JSON):\")\n",
    "    for i, json_str in enumerate(training_data_df['model_response'].head(3)):\n",
    "        try:\n",
    "            parsed_json = json.loads(json_str)\n",
    "            print(f\"JD {i+1} Model Response: {json.dumps(parsed_json, indent=2)}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JD {i+1} Model Response (Error parsing JSON): {json_str}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/training_data.csv' not found. Ensure it's in the 'data' folder at the project root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading training_data.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. Load and Inspect roles-based-on-skills.csv ---\n",
    "print(\"--- Loading roles-based-on-skills.csv ---\")\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    roles_skills_df = pd.read_csv(os.path.join('data', 'roles-based-on-skills.csv'))\n",
    "    print(\"roles-based-on-skills.csv loaded successfully!\")\n",
    "    \n",
    "    # Correct column name for Job Role for consistency\n",
    "    roles_skills_df.rename(columns={'Target': 'Job Role'}, inplace=True)\n",
    "\n",
    "    print(\"\\nFirst 5 rows of roles_skills_df after renaming:\")\n",
    "    print(roles_skills_df.head())\n",
    "    print(\"\\nInfo for roles_skills_df:\")\n",
    "    roles_skills_df.info()\n",
    "    print(\"\\nUnique Job Roles and their counts:\")\n",
    "    print(roles_skills_df['Job Role'].value_counts())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/roles-based-on-skills.csv' not found. Ensure it's in the 'data' folder at the project root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading roles-based-on-skills.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Prepare Data for Job Role Classification ---\n",
    "# This part will only run if the above data loading was successful\n",
    "X = roles_skills_df['ALL']  # The column containing all skills as a string\n",
    "y = roles_skills_df['Job Role'] # The target job role\n",
    "\n",
    "# 1. Feature Engineering: Convert text skills to numerical features using TF-IDF\n",
    "print(\"\\n--- Performing TF-IDF Vectorization ---\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limit features to top 5000 for efficiency\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "print(f\"Shape of TF-IDF matrix: {X_tfidf.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 2. Split Data into Training and Testing Sets\n",
    "print(\"\\n--- Splitting data into training and testing sets ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Model Training: Logistic Regression Classifier\n",
    "print(\"\\n--- Training Logistic Regression Model ---\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear') # Increased max_iter for convergence\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n--- Job Role Classification Pipeline Complete ---\")\n",
    "print(\"You now have a trained model that can predict job roles based on skills!\")\n",
    "\n",
    "\n",
    "# --- Save Trained Model and Vectorizer ---\n",
    "print(\"\\n--- Saving Trained Model and Vectorizer ---\")\n",
    "# Define paths to save the model and vectorizer within the backend/models folder\n",
    "# These paths are relative to the project root, which is now the current working directory.\n",
    "models_dir = os.path.join('backend', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True) # This creates the directory if it doesn't exist\n",
    "\n",
    "vectorizer_path = os.path.join(models_dir, 'tfidf_vectorizer.joblib')\n",
    "model_path = os.path.join(models_dir, 'job_role_classifier_model.joblib')\n",
    "\n",
    "# Save the TF-IDF Vectorizer\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "print(f\"TF-IDF Vectorizer saved to: {vectorizer_path}\")\n",
    "\n",
    "# Save the trained Logistic Regression Model\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Job Role Classifier Model saved to: {model_path}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f9628-4d3b-481e-95a7-fbb77a1e4ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f615f19c-8e8e-4c90-8fd3-24e3a26b036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Labeled Data for Job Description Parsing ---\n",
      "training_data.csv loaded successfully.\n",
      "Parsing 'model_response' column and extracting entities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 853/853 [00:00<00:00, 13243.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed Job Description DataFrame Head:\n",
      "                                     job_description  \\\n",
      "0  minimum qualifications\\nbachelors degree or eq...   \n",
      "1  description\\nas an asc you will be highly infl...   \n",
      "2  its an amazing time to be joining netflix as w...   \n",
      "3  description\\n\\nweb designers looking to expand...   \n",
      "4  at trackfive weve got big goals were on a miss...   \n",
      "\n",
      "                                     required_skills  \\\n",
      "0  Bachelor's degree or equivalent experience. Ex...   \n",
      "1  a passion to help people understand how apple ...   \n",
      "2  2+ years experience in preferably outbound lic...   \n",
      "3  2+ years experience in web design. Proficiency...   \n",
      "4  2+ years of experience with HTML and CSS/SASS,...   \n",
      "\n",
      "                                    experience_level  \\\n",
      "0  Experience managing enterprise SaaS accounts a...   \n",
      "1                                    years preferred   \n",
      "2  2+ years experience in preferably outbound lic...   \n",
      "3                                           2+ years   \n",
      "4                                           2+ years   \n",
      "\n",
      "                      educational_requirements  \n",
      "0  Bachelor's degree or equivalent experience.  \n",
      "1                                          N/A  \n",
      "2                                          N/A  \n",
      "3                                          N/A  \n",
      "4                                          N/A  \n",
      "\n",
      "Info for Parsed Job Description DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 853 entries, 0 to 852\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   job_description           853 non-null    object\n",
      " 1   required_skills           853 non-null    object\n",
      " 2   experience_level          853 non-null    object\n",
      " 3   educational_requirements  853 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 26.8+ KB\n",
      "\n",
      "Sample of Job Description and its Extracted Entities (first 3 entries):\n",
      "\n",
      "--- JD 1 ---\n",
      "Job Description (Snippet):\n",
      "minimum qualifications\n",
      "bachelors degree or equivalent practical experience years of experience in saas or productivity tools businessexperience managing enterprise accounts with sales cycles\n",
      "preferred qualifications\n",
      " years of experience building strategic business partnerships with enterprise customersability to work through and with a reseller ecosystem to scale the businessability to plan pitch and execute a territory business strategyability to build relationships and to deliver results in a ...\n",
      "Required Skills:\n",
      "Bachelor's degree or equivalent experience. Experience managing enterprise SaaS accounts and sales cycles.\n",
      "Experience Level:\n",
      "Experience managing enterprise SaaS accounts and sales cycles.\n",
      "Educational Requirements:\n",
      "Bachelor's degree or equivalent experience.\n",
      "\n",
      "--- JD 2 ---\n",
      "Job Description (Snippet):\n",
      "description\n",
      "as an asc you will be highly influential in growing mind and market share of apple products while building longterm relationships with those who share your passion \n",
      "customer experiences are driven through you and your partner team growing in an ever changing and challenging environment you strive for perfection whether its maintaining visual merchandising or helping to grow and develop your partner team\n",
      "\n",
      "qualifications\n",
      "a passion to help people understand how apple products can enrich...\n",
      "Required Skills:\n",
      "a passion to help people understand how apple products can enrich their livesexcellent communication skills allowing you to be as comfortable in front of a small group as you are speaking with individuals years preferred working in a dynamic sales andor results driven environment as well as proven success developing customer loyaltyability to encourage a partner team and grow apple business\n",
      "Experience Level:\n",
      "years preferred\n",
      "Educational Requirements:\n",
      "N/A\n",
      "\n",
      "--- JD 3 ---\n",
      "Job Description (Snippet):\n",
      "its an amazing time to be joining netflix as we continue to transform entertainment globally netflix is the worlds leading internet entertainment service with over  million paid memberships in over  countries enjoying tv series documentaries and feature films across a wide variety of genres and languages members can watch as much as they want anytime anywhere on any internetconnected screen members can play pause and resume watching all without commercials or commitments\n",
      "\n",
      "the consumer products t...\n",
      "Required Skills:\n",
      "2+ years experience in preferably outbound licensing. Understanding of category manufacturing and sales cycles for toys/food/beverage preferred. Experience with entertainment/lifestyle brands. Self-starter, proactive, flexible. Thrives under pressure. Superb organizational and multitasking skills. Excellent communication skills.\n",
      "Experience Level:\n",
      "2+ years experience in preferably outbound licensing\n",
      "Educational Requirements:\n",
      "N/A\n",
      "\n",
      "--- Labeled Data Preparation Complete ---\n",
      "This DataFrame (parsed_jd_df) is now suitable for training an NLP model (e.g., NER) to extract these entities from raw job descriptions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast # Used for literal evaluation of string representations of Python data structures\n",
    "from tqdm import tqdm # For progress bars, install if not available: pip install tqdm\n",
    "\n",
    "print(\"--- Preparing Labeled Data for Job Description Parsing ---\")\n",
    "\n",
    "# Load training_data.csv\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    training_data_df = pd.read_csv('data/training_data.csv')\n",
    "    print(\"training_data.csv loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/training_data.csv' not found. Please ensure it's in the 'data' folder at the project root and Jupyter is launched from the root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading training_data.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "parsed_jd_data = []\n",
    "\n",
    "# Process each row in the DataFrame to parse 'model_response'\n",
    "print(\"Parsing 'model_response' column and extracting entities...\")\n",
    "for index, row in tqdm(training_data_df.iterrows(), total=training_data_df.shape[0]):\n",
    "    job_description_text = row['job_description']\n",
    "    model_response_str = row['model_response']\n",
    "    \n",
    "    # Attempt to parse the JSON string\n",
    "    try:\n",
    "        parsed_response = json.loads(model_response_str)\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback for malformed JSON-like strings\n",
    "        try:\n",
    "            parsed_response = ast.literal_eval(model_response_str)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Skipping row {index} due to parsing error in 'model_response': {e}\")\n",
    "            continue\n",
    "\n",
    "    # Extract relevant entities. Extend this to other fields as needed.\n",
    "    required_skills_text = parsed_response.get('Required Skills', '')\n",
    "    experience_level_text = parsed_response.get('Experience Level', '')\n",
    "    educational_requirements_text = parsed_response.get('Educational Requirements', '')\n",
    "\n",
    "    parsed_jd_data.append({\n",
    "        'job_description': job_description_text,\n",
    "        'required_skills': required_skills_text,\n",
    "        'experience_level': experience_level_text,\n",
    "        'educational_requirements': educational_requirements_text,\n",
    "        # Add more fields here from 'model_response' as needed (e.g., \"Core Responsibilities\")\n",
    "    })\n",
    "\n",
    "# Convert the list of dictionaries to a new DataFrame\n",
    "parsed_jd_df = pd.DataFrame(parsed_jd_data)\n",
    "\n",
    "print(\"\\nParsed Job Description DataFrame Head:\")\n",
    "print(parsed_jd_df.head())\n",
    "\n",
    "print(\"\\nInfo for Parsed Job Description DataFrame:\")\n",
    "parsed_jd_df.info()\n",
    "\n",
    "print(\"\\nSample of Job Description and its Extracted Entities (first 3 entries):\")\n",
    "for i in range(3):\n",
    "    if i < len(parsed_jd_df):\n",
    "        print(f\"\\n--- JD {i+1} ---\")\n",
    "        print(f\"Job Description (Snippet):\\n{parsed_jd_df.loc[i, 'job_description'][:500]}...\") # Print first 500 chars\n",
    "        print(f\"Required Skills:\\n{parsed_jd_df.loc[i, 'required_skills']}\")\n",
    "        print(f\"Experience Level:\\n{parsed_jd_df.loc[i, 'experience_level']}\")\n",
    "        print(f\"Educational Requirements:\\n{parsed_jd_df.loc[i, 'educational_requirements']}\")\n",
    "\n",
    "print(\"\\n--- Labeled Data Preparation Complete ---\")\n",
    "print(\"This DataFrame (parsed_jd_df) is now suitable for training an NLP model (e.g., NER) to extract these entities from raw job descriptions.\")\n",
    "\n",
    "# Optional: Save this processed DataFrame for later use\n",
    "# You can uncomment the line below if you want to save this intermediate dataframe.\n",
    "# parsed_jd_df.to_csv('data/processed_jds_for_ner_training.csv', index=False)\n",
    "# print(\"\\nProcessed JD data saved to data/processed_jds_for_ner_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "624597ae-298a-4d93-a933-2d52df02b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: D:\\RESUME-ANALYSER-PROJECT\n",
      "Assuming it's already the project root or a parent directory.\n",
      "--- Loading master_resumes.jsonl ---\n",
      "master_resumes.jsonl loaded successfully!\n",
      "\n",
      "First 5 rows of master_resumes_df:\n",
      "                                       personal_info  \\\n",
      "0  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "1  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "2  {'name': 'Not Provided', 'email': 'Not Provide...   \n",
      "3  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "4  {'name': '', 'email': '', 'phone': '', 'locati...   \n",
      "\n",
      "                                          experience  \\\n",
      "0  [{'company': 'Fresher', 'company_info': {'indu...   \n",
      "1  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
      "2  [{'company': 'Parkar Consulting and Labs', 'co...   \n",
      "3  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
      "4  [{'company': 'Atos Syntel', 'company_info': {'...   \n",
      "\n",
      "                                           education  \\\n",
      "0  [{'degree': {'level': 'ME', 'field': 'Computer...   \n",
      "1  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
      "2  [{'degree': {'level': 'B.E.', 'field': 'Not Pr...   \n",
      "3  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
      "4  [{'degree': {'level': 'Bachelor of Engineering...   \n",
      "\n",
      "                                              skills  \\\n",
      "0  {'technical': {'programming_languages': [{'nam...   \n",
      "1  {'technical': {'project_management': [{'name':...   \n",
      "2  {'technical': {'programming_languages': [{'nam...   \n",
      "3  {'technical': {'project_management': [{'name':...   \n",
      "4  {'technical': {'programming_languages': [{'nam...   \n",
      "\n",
      "                                            projects  \\\n",
      "0  [{'name': 'Unknown', 'description': 'Unknown',...   \n",
      "1  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
      "2  [{'name': 'FPGA Implementation', 'description'...   \n",
      "3  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
      "4                                                 []   \n",
      "\n",
      "                                      certifications  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                                      \n",
      "4  {\"name\": \"ESD Program\", \"issuer\": \"Zensar Tech...   \n",
      "\n",
      "                                        achievements  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  [Treasurer in IEEE student branch at JSCOE, Pu...   \n",
      "\n",
      "                                           workshops publications  \\\n",
      "0                                                NaN          NaN   \n",
      "1                                                NaN          NaN   \n",
      "2                                                NaN          NaN   \n",
      "3                                                NaN          NaN   \n",
      "4  [{'name': 'Medical IoT', 'issuer': 'IEEE Stand...          NaN   \n",
      "\n",
      "  teaching_experience internships  \n",
      "0                 NaN         NaN  \n",
      "1                 NaN         NaN  \n",
      "2                 NaN         NaN  \n",
      "3                 NaN         NaN  \n",
      "4                 NaN         NaN  \n",
      "\n",
      "Info for master_resumes_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4817 entries, 0 to 4816\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   personal_info        4816 non-null   object\n",
      " 1   experience           4817 non-null   object\n",
      " 2   education            4817 non-null   object\n",
      " 3   skills               4817 non-null   object\n",
      " 4   projects             4806 non-null   object\n",
      " 5   certifications       4817 non-null   object\n",
      " 6   achievements         4 non-null      object\n",
      " 7   workshops            4 non-null      object\n",
      " 8   publications         3 non-null      object\n",
      " 9   teaching_experience  1 non-null      object\n",
      " 10  internships          2 non-null      object\n",
      "dtypes: object(11)\n",
      "memory usage: 414.1+ KB\n",
      "\n",
      "Sample of 'skills' column from master_resumes_df (first 3 entries):\n",
      "Resume 1 Skills: {'technical': {'programming_languages': [{'name': 'Python', 'level': 'intermediate'}, {'name': 'C++', 'level': 'intermediate'}, {'name': 'C', 'level': 'intermediate'}], 'frameworks': [{'name': 'Tensorflow', 'level': 'intermediate'}, {'name': 'Numpy', 'level': 'intermediate'}], 'databases': [{'name': 'MySQL', 'level': 'intermediate'}], 'cloud': [{'name': 'Unknown', 'level': 'Unknown'}]}, 'languages': [{'name': 'Unknown', 'level': 'Unknown'}]}\n",
      "Resume 2 Skills: {'technical': {'project_management': [{'name': 'Project Execution', 'level': 'expert'}, {'name': 'Quality Management', 'level': 'advanced'}, {'name': 'Budget Monitoring', 'level': 'advanced'}], 'automation': [{'name': 'PLC Programming', 'level': 'advanced'}, {'name': 'SCADA Systems', 'level': 'advanced'}], 'software_tools': [{'name': 'SAP', 'level': 'intermediate'}, {'name': 'Microsoft Visio', 'level': 'intermediate'}]}, 'languages': [{'name': 'English', 'level': 'fluent'}]}\n",
      "Resume 3 Skills: {'technical': {'programming_languages': [{'name': 'C', 'level': 'Basic'}, {'name': 'SQL', 'level': 'Basic'}, {'name': 'PL/SQL', 'level': 'Basic'}, {'name': 'JAVA', 'level': 'Basic'}, {'name': 'JAVAEE', 'level': 'Basic'}, {'name': 'Javascript', 'level': 'Basic'}, {'name': 'HTML', 'level': 'Basic'}, {'name': 'CSS', 'level': 'Basic'}, {'name': 'jquery', 'level': 'Basic'}, {'name': 'mysql', 'level': 'Basic'}, {'name': 'Spring', 'level': 'Basic'}, {'name': 'Hibernate', 'level': 'Basic'}, {'name': 'Python', 'level': 'Basic'}], 'frameworks': [{'name': 'Not Provided', 'level': 'Not Provided'}], 'databases': [{'name': 'Not Provided', 'level': 'Not Provided'}], 'cloud': [{'name': 'AWS', 'level': 'Not Provided'}]}, 'languages': [{'name': 'English', 'level': 'Not Provided'}]}\n",
      "\n",
      "\n",
      "--- Loading training_data.csv ---\n",
      "training_data.csv loaded successfully!\n",
      "\n",
      "First 5 rows of training_data_df:\n",
      "  company_name                                    job_description  \\\n",
      "0       Google  minimum qualifications\\nbachelors degree or eq...   \n",
      "1        Apple  description\\nas an asc you will be highly infl...   \n",
      "2      Netflix  its an amazing time to be joining netflix as w...   \n",
      "3  Robert Half  description\\n\\nweb designers looking to expand...   \n",
      "4    TrackFive  at trackfive weve got big goals were on a miss...   \n",
      "\n",
      "                              position_title  description_length  \\\n",
      "0                           Sales Specialist                2727   \n",
      "1                 Apple Solutions Consultant                 828   \n",
      "2  Licensing Coordinator - Consumer Products                3205   \n",
      "3                               Web Designer                2489   \n",
      "4                              Web Developer                3167   \n",
      "\n",
      "                                      model_response  \n",
      "0   {\\n  \"Core Responsibilities\": \"Responsible fo...  \n",
      "1   {\\n  \"Core Responsibilities\": \"as an asc you ...  \n",
      "2   {\\n  \"Core Responsibilities\": \"Help drive bus...  \n",
      "3   {\\n  \"Core Responsibilities\": \"Designing webs...  \n",
      "4   {\\n  \"Core Responsibilities\": \"Build and layo...  \n",
      "\n",
      "Info for training_data_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 853 entries, 0 to 852\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   company_name        853 non-null    object\n",
      " 1   job_description     853 non-null    object\n",
      " 2   position_title      853 non-null    object\n",
      " 3   description_length  853 non-null    int64 \n",
      " 4   model_response      853 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 33.4+ KB\n",
      "\n",
      "Sample of 'model_response' column from training_data_df (first 3 entries, parsed JSON):\n",
      "JD 1 Model Response: {\n",
      "  \"Core Responsibilities\": \"Responsible for expanding Google Workspace product adoption across an assigned territory. Build relationships with customers to understand needs and provide Google Workspace solutions. Partner with account teams to construct solutions and grow business for Google Workspace.\",\n",
      "  \"Required Skills\": \"Bachelor's degree or equivalent experience. Experience managing enterprise SaaS accounts and sales cycles.\",\n",
      "  \"Educational Requirements\": \"Bachelor's degree or equivalent experience.\",\n",
      "  \"Experience Level\": \"Experience managing enterprise SaaS accounts and sales cycles.\",\n",
      "  \"Preferred Qualifications\": \"Experience building strategic partnerships with enterprise customers. Ability to work through a reseller ecosystem. Excellent communication and strategic thinking skills.\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "JD 2 Model Response: {\n",
      "  \"Core Responsibilities\": \"as an asc you will be highly influential in growing mind and market share of apple products while building longterm relationships with those who share your passion customer experiences are driven through you and your partner team growing in an ever changing and challenging environment you strive for perfection whether its maintaining visual merchandising or helping to grow and develop your partner team\",\n",
      "  \"Required Skills\": \"a passion to help people understand how apple products can enrich their livesexcellent communication skills allowing you to be as comfortable in front of a small group as you are speaking with individuals years preferred working in a dynamic sales andor results driven environment as well as proven success developing customer loyaltyability to encourage a partner team and grow apple business\",\n",
      "  \"Educational Requirements\": \"N/A\",\n",
      "  \"Experience Level\": \"years preferred\",\n",
      "  \"Preferred Qualifications\": \"N/A\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "JD 3 Model Response: {\n",
      "  \"Core Responsibilities\": \"Help drive business by supporting licensing managers on tasks related to category management, facilitating information between stakeholders, maintaining communication plans. Coordinate with internal teams to share brand and marketing updates with partners. Maintain and update title strategies and licensing plans. Collaborate with partners on product launches. Assist with licensing recaps, meetings, and agreements.\",\n",
      "  \"Required Skills\": \"2+ years experience in preferably outbound licensing. Understanding of category manufacturing and sales cycles for toys/food/beverage preferred. Experience with entertainment/lifestyle brands. Self-starter, proactive, flexible. Thrives under pressure. Superb organizational and multitasking skills. Excellent communication skills.\",\n",
      "  \"Educational Requirements\": \"N/A\",\n",
      "  \"Experience Level\": \"2+ years experience in preferably outbound licensing\",\n",
      "  \"Preferred Qualifications\": \"Understanding of category manufacturing and sales cycles for toys and/or food and beverage preferred. Experience working with reputable entertainment and/or lifestyle brands.\",\n",
      "  \"Compensation and Benefits\": \"N/A\"\n",
      "}\n",
      "\n",
      "\n",
      "--- Loading roles-based-on-skills.csv ---\n",
      "roles-based-on-skills.csv loaded successfully!\n",
      "\n",
      "First 5 rows of roles_skills_df after renaming:\n",
      "   Unnamed: 0           Job Role  \\\n",
      "0           0  Software Engineer   \n",
      "1           1  Software Engineer   \n",
      "2           2  Software Engineer   \n",
      "3           3  Software Engineer   \n",
      "4           4  Software Engineer   \n",
      "\n",
      "                                                 ALL  \n",
      "0  Java Android Development PHP HTML C Cascading ...  \n",
      "1                                                ...  \n",
      "2  JavaScript Reactjs MySQL ObjectOriented Progra...  \n",
      "3  Java JavaScript PHP HTML Cascading Style Sheet...  \n",
      "4  Java Android Development C Communication HTML ...  \n",
      "\n",
      "Info for roles_skills_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4576 entries, 0 to 4575\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4576 non-null   int64 \n",
      " 1   Job Role    4576 non-null   object\n",
      " 2   ALL         4576 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 107.4+ KB\n",
      "\n",
      "Unique Job Roles and their counts:\n",
      "Job Role\n",
      "Software Engineer            667\n",
      "Quality Assurance            502\n",
      "Network Engineer             491\n",
      "Business Analyst             490\n",
      "Machine Learning Engineer    486\n",
      "DevOps                       468\n",
      "Data Science                 418\n",
      "Cyber Security               392\n",
      "Mobile App Developer         390\n",
      "Data Engineer                272\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Performing TF-IDF Vectorization ---\n",
      "Shape of TF-IDF matrix: (4576, 5000)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Splitting data into training and testing sets ---\n",
      "Training set size: 3660 samples\n",
      "Testing set size: 916 samples\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Logistic Regression Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANIRUDDH\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Accuracy: 0.8908\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         Business Analyst       0.93      0.96      0.94        98\n",
      "           Cyber Security       0.97      0.91      0.94        78\n",
      "            Data Engineer       0.78      0.57      0.66        54\n",
      "             Data Science       0.86      0.83      0.85        84\n",
      "                   DevOps       0.93      0.90      0.92        94\n",
      "Machine Learning Engineer       0.80      0.82      0.81        97\n",
      "     Mobile App Developer       0.96      0.95      0.95        78\n",
      "         Network Engineer       0.88      0.93      0.91        98\n",
      "        Quality Assurance       0.98      0.95      0.96       101\n",
      "        Software Engineer       0.82      0.93      0.87       134\n",
      "\n",
      "                 accuracy                           0.89       916\n",
      "                macro avg       0.89      0.88      0.88       916\n",
      "             weighted avg       0.89      0.89      0.89       916\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Job Role Classification Pipeline Complete ---\n",
      "You now have a trained model that can predict job roles based on skills!\n",
      "\n",
      "--- Saving Trained Model and Vectorizer ---\n",
      "TF-IDF Vectorizer saved to: backend\\models\\tfidf_vectorizer.joblib\n",
      "Job Role Classifier Model saved to: backend\\models\\job_role_classifier_model.joblib\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import re # <-- CRITICAL: Added this import\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- CRITICAL: Change working directory to the project root ---\n",
    "# This approach is more robust for Jupyter Notebooks as it doesn't rely on __file__.\n",
    "# It assumes the notebook is in a 'notebooks/' subfolder directly under the project root.\n",
    "try:\n",
    "    current_working_dir = os.getcwd()\n",
    "    # Check if the current working directory ends with 'notebooks'\n",
    "    if current_working_dir.endswith(os.path.join('notebooks', '')) or current_working_dir.endswith('notebooks'):\n",
    "        # Go up one level to the project root\n",
    "        project_root_dir = os.path.abspath(os.path.join(current_working_dir, os.pardir))\n",
    "        os.chdir(project_root_dir)\n",
    "        print(f\"Changed working directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Current working directory: {current_working_dir}\")\n",
    "        print(\"Assuming it's already the project root or a parent directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error changing directory. Please ensure your notebook is run from within the 'notebooks' folder, or that the 'notebooks' folder is directly under your project root: {e}\")\n",
    "    exit() # Exit if we can't set the correct working directory\n",
    "\n",
    "\n",
    "# --- 1. Load and Inspect master_resumes.jsonl ---\n",
    "print(\"--- Loading master_resumes.jsonl ---\")\n",
    "resumes_data = []\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    with open(os.path.join('data', 'master_resumes.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            resumes_data.append(json.loads(line))\n",
    "    master_resumes_df = pd.DataFrame(resumes_data)\n",
    "    print(\"master_resumes.jsonl loaded successfully!\")\n",
    "    print(\"\\nFirst 5 rows of master_resumes_df:\")\n",
    "    print(master_resumes_df.head())\n",
    "    print(\"\\nInfo for master_resumes_df:\")\n",
    "    master_resumes_df.info()\n",
    "    print(\"\\nSample of 'skills' column from master_resumes_df (first 3 entries):\")\n",
    "    for i, skills in enumerate(master_resumes_df['skills'].head(3)):\n",
    "        print(f\"Resume {i+1} Skills: {skills}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/master_resumes.jsonl' not found. Ensure it's in the 'data' folder at the project root and Jupyter is launched from the root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading master_resumes.jsonl: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 2. Load and Inspect training_data.csv ---\n",
    "print(\"--- Loading training_data.csv ---\")\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    training_data_df = pd.read_csv(os.path.join('data', 'training_data.csv'))\n",
    "    print(\"training_data.csv loaded successfully!\")\n",
    "    print(\"\\nFirst 5 rows of training_data_df:\")\n",
    "    print(training_data_df.head())\n",
    "    print(\"\\nInfo for training_data_df:\")\n",
    "    training_data_df.info()\n",
    "    \n",
    "    print(\"\\nSample of 'model_response' column from training_data_df (first 3 entries, parsed JSON):\")\n",
    "    for i, json_str in enumerate(training_data_df['model_response'].head(3)):\n",
    "        try:\n",
    "            parsed_json = json.loads(json_str)\n",
    "            print(f\"JD {i+1} Model Response: {json.dumps(parsed_json, indent=2)}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JD {i+1} Model Response (Error parsing JSON): {json_str}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/training_data.csv' not found. Ensure it's in the 'data' folder at the project root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading training_data.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. Load and Inspect roles-based-on-skills.csv ---\n",
    "print(\"--- Loading roles-based-on-skills.csv ---\")\n",
    "try:\n",
    "    # Path is relative to the project root\n",
    "    roles_skills_df = pd.read_csv(os.path.join('data', 'roles-based-on-skills.csv'))\n",
    "    print(\"roles-based-on-skills.csv loaded successfully!\")\n",
    "    \n",
    "    # Correct column name for Job Role for consistency\n",
    "    roles_skills_df.rename(columns={'Target': 'Job Role'}, inplace=True)\n",
    "\n",
    "    print(\"\\nFirst 5 rows of roles_skills_df after renaming:\")\n",
    "    print(roles_skills_df.head())\n",
    "    print(\"\\nInfo for roles_skills_df:\")\n",
    "    roles_skills_df.info()\n",
    "    print(\"\\nUnique Job Roles and their counts:\")\n",
    "    print(roles_skills_df['Job Role'].value_counts())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data/roles-based-on-skills.csv' not found. Ensure it's in the 'data' folder at the project root.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading roles-based-on-skills.csv: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Prepare Data for Job Role Classification ---\n",
    "X = roles_skills_df['ALL']  # The column containing all skills as a string\n",
    "y = roles_skills_df['Job Role'] # The target job role\n",
    "\n",
    "# 1. Feature Engineering: Convert text skills to numerical features using TF-IDF\n",
    "print(\"\\n--- Performing TF-IDF Vectorization ---\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limit features to top 5000 for efficiency\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "print(f\"Shape of TF-IDF matrix: {X_tfidf.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 2. Split Data into Training and Testing Sets\n",
    "print(\"\\n--- Splitting data into training and testing sets ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Model Training: Logistic Regression Classifier\n",
    "print(\"\\n--- Training Logistic Regression Model ---\")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear') # Increased max_iter for convergence\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n--- Job Role Classification Pipeline Complete ---\")\n",
    "print(\"You now have a trained model that can predict job roles based on skills!\")\n",
    "\n",
    "\n",
    "# --- Save Trained Model and Vectorizer ---\n",
    "print(\"\\n--- Saving Trained Model and Vectorizer ---\")\n",
    "# Define paths to save the model and vectorizer within the backend/models folder\n",
    "# These paths are relative to the project root, which is now the current working directory.\n",
    "models_dir = os.path.join('backend', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True) # This creates the directory if it doesn't exist\n",
    "\n",
    "vectorizer_path = os.path.join(models_dir, 'tfidf_vectorizer.joblib')\n",
    "model_path = os.path.join(models_dir, 'job_role_classifier_model.joblib')\n",
    "\n",
    "# Save the TF-IDF Vectorizer\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "print(f\"TF-IDF Vectorizer saved to: {vectorizer_path}\")\n",
    "\n",
    "# Save the trained Logistic Regression Model\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Job Role Classifier Model saved to: {model_path}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14bb873e-2e43-4e0b-a0c6-3fc13987c1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Data for spaCy Custom NER Training (with Overlap Resolution) ---\n",
      "Creating spaCy training examples (text and entity spans) with overlap resolution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 853/853 [00:00<00:00, 1217.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 89 spaCy training examples after overlap resolution.\n",
      "Training examples: 71\n",
      "Validation examples: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train data: 100%|██████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 161.78it/s]\n",
      "Processing dev data: 100%|████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 264.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved to: data/spacy_training_data\\train.spacy\n",
      "Validation data saved to: data/spacy_training_data\\dev.spacy\n",
      "\n",
      "--- spaCy Data Preparation Complete. Ready for Training! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import spacy\n",
    "from tqdm import tqdm # For progress bars, install if not available: pip install tqdm\n",
    "import random # For splitting data\n",
    "from spacy.tokens import DocBin # For saving data in spaCy's format\n",
    "import re # IMPORTANT: Ensure this is imported for regex operations\n",
    "\n",
    "print(\"\\n--- Preparing Data for spaCy Custom NER Training (with Overlap Resolution) ---\")\n",
    "\n",
    "# Ensure spaCy model is loaded for tokenization (even if not using its NER initially)\n",
    "try:\n",
    "    nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"SpaCy model 'en_core_web_sm' not found. Running: python -m spacy download en_core_web_sm\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    # After download, it's CRITICAL to restart the kernel for spaCy to load dependencies correctly.\n",
    "    print(\"Downloaded 'en_core_web_sm'. Please RESTART YOUR JUPYTER KERNEL (Kernel -> Restart) and run all cells again.\")\n",
    "    exit() # Exit to force kernel restart\n",
    "\n",
    "# Assuming parsed_jd_df from the previous cell is available in your notebook\n",
    "if 'parsed_jd_df' not in locals():\n",
    "    print(\"Error: 'parsed_jd_df' not found. Please run the previous cell to load and parse training_data.csv.\")\n",
    "    exit()\n",
    "\n",
    "# List to store spaCy-compatible training examples\n",
    "training_examples = []\n",
    "\n",
    "# Define the entities we want to extract and map them to their corresponding columns\n",
    "ENTITY_COLUMNS = { # Corrected variable name here\n",
    "    'REQUIRED_SKILLS': 'required_skills',\n",
    "    'EXPERIENCE_LEVEL': 'experience_level',\n",
    "    'EDUCATIONAL_REQUIREMENTS': 'educational_requirements'\n",
    "}\n",
    "\n",
    "# Iterate through the parsed job description data\n",
    "print(\"Creating spaCy training examples (text and entity spans) with overlap resolution...\")\n",
    "for index, row in tqdm(parsed_jd_df.iterrows(), total=parsed_jd_df.shape[0]):\n",
    "    text = str(row['job_description']) # Ensure job_description is treated as string\n",
    "    candidate_entities = [] # Collect all potential entities first\n",
    "\n",
    "    # Process each entity type\n",
    "    for entity_type, col_name in ENTITY_COLUMNS.items(): # Corrected variable name here\n",
    "        entity_text = str(row[col_name]).strip() # Ensure it's a string and strip whitespace\n",
    "        \n",
    "        # Skip if entity text is empty or common placeholders\n",
    "        if not entity_text or entity_text.lower() in [\"n/a\", \"not provided\", \"unknown\", \"none\"]:\n",
    "            continue\n",
    "\n",
    "        # Find all occurrences of the entity text in the job description\n",
    "        # Using re.finditer to get start and end indices for all matches\n",
    "        for match in re.finditer(re.escape(entity_text), text, re.IGNORECASE | re.DOTALL):\n",
    "            start, end = match.span()\n",
    "            # Basic validation: ensure the span makes sense\n",
    "            if start < end and end <= len(text):\n",
    "                matched_snippet = text[start:end]\n",
    "                # Ensure the case-insensitive match is a substantial match to the entity text\n",
    "                if matched_snippet.lower() == entity_text.lower():\n",
    "                    candidate_entities.append({'start': start, 'end': end, 'label': entity_type, 'text': matched_snippet})\n",
    "\n",
    "    # --- Overlap Resolution Logic ---\n",
    "    # Sort candidates: prioritize longer spans, then by start position\n",
    "    candidate_entities.sort(key=lambda x: (x['end'] - x['start'], -x['start']), reverse=True) # Longest first, then earliest\n",
    "    \n",
    "    final_entities = []\n",
    "    # Keep track of covered token indices (approximate) or character ranges\n",
    "    covered_ranges = []\n",
    "\n",
    "    for cand_ent in candidate_entities:\n",
    "        is_overlapping = False\n",
    "        # Check if the candidate entity overlaps with any already accepted entity\n",
    "        for final_ent in final_entities:\n",
    "            # Check for any overlap: [start1, end1) and [start2, end2) overlap if max(start1, start2) < min(end1, end2)\n",
    "            if max(cand_ent['start'], final_ent['start']) < min(cand_ent['end'], final_ent['end']):\n",
    "                is_overlapping = True\n",
    "                break\n",
    "        \n",
    "        if not is_overlapping:\n",
    "            final_entities.append(cand_ent)\n",
    "\n",
    "    # Convert final_entities to the (start, end, label) tuple format required by spaCy\n",
    "    spacy_ents = [(ent['start'], ent['end'], ent['label']) for ent in final_entities]\n",
    "    \n",
    "    if spacy_ents: # Only add if there are valid, non-overlapping entities\n",
    "        training_examples.append((text, {\"entities\": spacy_ents}))\n",
    "    else:\n",
    "        # It's okay to have documents without entities (negative examples),\n",
    "        # but for this specific dataset and simplified pipeline,\n",
    "        # we focus on documents with at least one found entity.\n",
    "        pass\n",
    "\n",
    "\n",
    "print(f\"\\nGenerated {len(training_examples)} spaCy training examples after overlap resolution.\")\n",
    "\n",
    "# --- Split Data into Training and Validation Sets ---\n",
    "random.seed(42)\n",
    "random.shuffle(training_examples)\n",
    "\n",
    "split_point = int(len(training_examples) * 0.8)\n",
    "train_data = training_examples[:split_point]\n",
    "dev_data = training_examples[split_point:]\n",
    "\n",
    "print(f\"Training examples: {len(train_data)}\")\n",
    "print(f\"Validation examples: {len(dev_data)}\")\n",
    "\n",
    "# --- Save Data in spaCy's Binary Format (.spacy) ---\n",
    "output_dir = 'data/spacy_training_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_docbin = DocBin()\n",
    "for text, annot in tqdm(train_data, desc=\"Processing train data\"):\n",
    "    doc = nlp_sm.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None: # char_span returns None if character indices don't align perfectly with tokens\n",
    "            ents.append(span)\n",
    "    try:\n",
    "        doc.ents = ents # Assign entities\n",
    "        train_docbin.add(doc)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping document due to ValueError after span creation: {e} in text: '{text[:200]}...'\")\n",
    "\n",
    "\n",
    "dev_docbin = DocBin()\n",
    "for text, annot in tqdm(dev_data, desc=\"Processing dev data\"):\n",
    "    doc = nlp_sm.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    try:\n",
    "        doc.ents = ents\n",
    "        dev_docbin.add(doc)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping dev document due to ValueError after span creation: {e} in text: '{text[:200]}...'\")\n",
    "\n",
    "\n",
    "train_docbin.to_disk(os.path.join(output_dir, \"train.spacy\"))\n",
    "print(f\"Train data saved to: {os.path.join(output_dir, 'train.spacy')}\")\n",
    "\n",
    "\n",
    "dev_docbin.to_disk(os.path.join(output_dir, \"dev.spacy\"))\n",
    "print(f\"Validation data saved to: {os.path.join(output_dir, 'dev.spacy')}\")\n",
    "\n",
    "print(\"\\n--- spaCy Data Preparation Complete. Ready for Training! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2bbda63-393d-4900-921d-81950f19f2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated and saved clean config to: configs\\ner_transformer_config.cfg\n",
      "Now proceed to train the model using the command in your terminal.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "# from spacy.util import to_disk # No longer explicitly importing, will use method directly\n",
    "\n",
    "# Define the configuration as a Python dictionary\n",
    "config_dict = {\n",
    "    \"paths\": {\n",
    "        \"train\": \"data/spacy_training_data/train.spacy\",\n",
    "        \"dev\": \"data/spacy_training_data/dev.spacy\",\n",
    "        \"vectors\": None,\n",
    "        \"init_tok2vec\": None\n",
    "    },\n",
    "    \"system\": {\n",
    "        \"gpu_allocator\": None,\n",
    "        \"seed\": 0\n",
    "    },\n",
    "    \"nlp\": {\n",
    "        \"lang\": \"en\",\n",
    "        \"pipeline\": [\"transformer\", \"ner\"],\n",
    "        \"batch_size\": 128,\n",
    "        \"disabled\": [],\n",
    "        \"before_creation\": None,\n",
    "        \"after_creation\": None,\n",
    "        \"after_pipeline_creation\": None,\n",
    "        \"tokenizer\": {\"@tokenizers\":\"spacy.Tokenizer.v1\"},\n",
    "        \"vectors\": {\"@vectors\":\"spacy.Vectors.v1\"}\n",
    "    },\n",
    "    \"components\": {\n",
    "        \"transformer\": {\n",
    "            \"factory\": \"transformer\",\n",
    "            \"max_batch_items\": 4096,\n",
    "            \"set_extra_annotations\": {\"from_tokenizer\": True},\n",
    "            \"model\": {\n",
    "                \"@architectures\": \"spacy-transformers.TransformerModel.v3\",\n",
    "                \"name\": \"bert-base-uncased\", # Set your desired transformer model here\n",
    "                \"tokenizer_config\": {\"use_fast\": True},\n",
    "                \"grad_factor\": 1.0\n",
    "            }\n",
    "        },\n",
    "        \"ner\": {\n",
    "            \"factory\": \"ner\",\n",
    "            \"incorrect_spans_key\": None,\n",
    "            \"moves\": None,\n",
    "            \"scorer\": {\"@scorers\":\"spacy.ner_scorer.v1\"},\n",
    "            \"update_with_oracle_cut_size\": 100,\n",
    "            \"model\": {\n",
    "                \"@architectures\": \"spacy.TransitionBasedParser.v2\",\n",
    "                \"state_type\": \"ner\",\n",
    "                \"extra_state_tokens\": False,\n",
    "                \"hidden_width\": 64,\n",
    "                \"maxout_pieces\": 2,\n",
    "                \"use_upper\": True,\n",
    "                \"nO\": None,\n",
    "                \"tok2vec\": {\n",
    "                    \"@architectures\": \"spacy-transformers.TransformerListener.v1\",\n",
    "                    \"upstream\": \"*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"corpora\": {\n",
    "        \"dev\": {\n",
    "            \"@readers\": \"spacy.Corpus.v1\",\n",
    "            \"path\": {\"@variables\":\"${paths.dev}\"},\n",
    "            \"max_length\": 0,\n",
    "            \"gold_preproc\": False,\n",
    "            \"limit\": 0,\n",
    "            \"augmenter\": None\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"@readers\": \"spacy.Corpus.v1\",\n",
    "            \"path\": {\"@variables\":\"${paths.train}\"},\n",
    "            \"max_length\": 0,\n",
    "            \"gold_preproc\": False,\n",
    "            \"limit\": 0,\n",
    "            \"augmenter\": None\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"dev_corpus\": \"corpora.dev\",\n",
    "        \"train_corpus\": \"corpora.train\",\n",
    "        \"seed\": {\"@variables\":\"${system.seed}\"},\n",
    "        \"gpu_allocator\": {\"@variables\":\"${system.gpu_allocator}\"},\n",
    "        \"dropout\": 0.1,\n",
    "        \"accumulate_gradient\": 1,\n",
    "        \"patience\": 1600,\n",
    "        \"max_epochs\": 0,\n",
    "        \"max_steps\": 20000,\n",
    "        \"eval_frequency\": 200,\n",
    "        \"frozen_components\": [],\n",
    "        \"annotating_components\": [],\n",
    "        \"before_to_disk\": None,\n",
    "        \"before_update\": None,\n",
    "        \"batcher\": {\n",
    "            \"@batchers\": \"spacy.batch_by_words.v1\",\n",
    "            \"discard_oversize\": False,\n",
    "            \"tolerance\": 0.2,\n",
    "            \"get_length\": None,\n",
    "            \"size\": {\n",
    "                \"@schedules\": \"compounding.v1\",\n",
    "                \"start\": 100,\n",
    "                \"stop\": 1000,\n",
    "                \"compound\": 1.001,\n",
    "                \"t\": 0.0\n",
    "            }\n",
    "        },\n",
    "        \"logger\": {\n",
    "            \"@loggers\": \"spacy.ConsoleLogger.v1\",\n",
    "            \"progress_bar\": False\n",
    "        },\n",
    "        \"optimizer\": {\n",
    "            \"@optimizers\": \"Adam.v1\",\n",
    "            \"beta1\": 0.9,\n",
    "            \"beta2\": 0.999,\n",
    "            \"L2_is_weight_decay\": True,\n",
    "            \"L2\": 0.01,\n",
    "            \"grad_clip\": 1.0,\n",
    "            \"use_averages\": False,\n",
    "            \"eps\": 0.00000001,\n",
    "            \"learn_rate\": 0.001\n",
    "        },\n",
    "        \"score_weights\": {\n",
    "            \"ents_f\": 1.0,\n",
    "            \"ents_p\": 0.0,\n",
    "            \"ents_r\": 0.0,\n",
    "            \"ents_per_type\": None\n",
    "        }\n",
    "    },\n",
    "    \"pretraining\": {},\n",
    "    \"initialize\": {\n",
    "        \"vectors\": {\"@variables\":\"${paths.vectors}\"},\n",
    "        \"init_tok2vec\": {\"@variables\":\"${paths.init_tok2vec}\"},\n",
    "        \"vocab_data\": None,\n",
    "        \"lookups\": None,\n",
    "        \"before_init\": None,\n",
    "        \"after_init\": None,\n",
    "        \"components\": {},\n",
    "        \"tokenizer\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ensure the 'configs' directory exists\n",
    "configs_dir = 'configs'\n",
    "os.makedirs(configs_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the config file\n",
    "config_file_path = os.path.join(configs_dir, 'ner_transformer_config.cfg')\n",
    "\n",
    "# Convert the dictionary to a spaCy Config object and save it\n",
    "# We are now using the .to_disk() method directly on the Config object,\n",
    "# which does not take an 'exclude' argument for a Config object.\n",
    "spacy_config = spacy.util.Config(config_dict)\n",
    "spacy_config.to_disk(config_file_path) # Removed exclude=None\n",
    "\n",
    "print(f\"Generated and saved clean config to: {config_file_path}\")\n",
    "print(\"Now proceed to train the model using the command in your terminal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2136fc-22ed-413f-9000-37413b85d72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
