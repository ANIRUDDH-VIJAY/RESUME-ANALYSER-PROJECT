{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f4b098-d30c-445c-b5e9-caca6d6748e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: D:\\RESUME-ANALYSER-PROJECT\\notebooks\n",
      "--------------------------------------------------\n",
      "--- Loading master_resumes.jsonl ---\n",
      "master_resumes.jsonl loaded successfully!\n",
      "Number of samples: 4817\n",
      "\n",
      "First 3 rows of master_resumes_df:\n",
      "                                       personal_info  \\\n",
      "0  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "1  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
      "2  {'name': 'Not Provided', 'email': 'Not Provide...   \n",
      "\n",
      "                                          experience  \\\n",
      "0  [{'company': 'Fresher', 'company_info': {'indu...   \n",
      "1  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
      "2  [{'company': 'Parkar Consulting and Labs', 'co...   \n",
      "\n",
      "                                           education  \\\n",
      "0  [{'degree': {'level': 'ME', 'field': 'Computer...   \n",
      "1  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
      "2  [{'degree': {'level': 'B.E.', 'field': 'Not Pr...   \n",
      "\n",
      "                                              skills  \\\n",
      "0  {'technical': {'programming_languages': [{'nam...   \n",
      "1  {'technical': {'project_management': [{'name':...   \n",
      "2  {'technical': {'programming_languages': [{'nam...   \n",
      "\n",
      "                                            projects certifications  \\\n",
      "0  [{'name': 'Unknown', 'description': 'Unknown',...                  \n",
      "1  [{'name': 'FGP/WPMP', 'description': 'Led syst...                  \n",
      "2  [{'name': 'FPGA Implementation', 'description'...                  \n",
      "\n",
      "  achievements workshops publications teaching_experience internships  \n",
      "0          NaN       NaN          NaN                 NaN         NaN  \n",
      "1          NaN       NaN          NaN                 NaN         NaN  \n",
      "2          NaN       NaN          NaN                 NaN         NaN  \n",
      "--------------------------------------------------\n",
      "--- Loading training_data.csv (for Job Description analysis) ---\n",
      "training_data.csv loaded successfully!\n",
      "Number of samples: 853\n",
      "\n",
      "First 3 rows of training_data_df:\n",
      "  company_name                                    job_description  \\\n",
      "0       Google  minimum qualifications\\nbachelors degree or eq...   \n",
      "1        Apple  description\\nas an asc you will be highly infl...   \n",
      "2      Netflix  its an amazing time to be joining netflix as w...   \n",
      "\n",
      "                              position_title  description_length  \\\n",
      "0                           Sales Specialist                2727   \n",
      "1                 Apple Solutions Consultant                 828   \n",
      "2  Licensing Coordinator - Consumer Products                3205   \n",
      "\n",
      "                                      model_response  \n",
      "0   {\\n  \"Core Responsibilities\": \"Responsible fo...  \n",
      "1   {\\n  \"Core Responsibilities\": \"as an asc you ...  \n",
      "2   {\\n  \"Core Responsibilities\": \"Help drive bus...  \n",
      "--------------------------------------------------\n",
      "--- Loading roles-based-on-skills.csv (for Job Role Classification) ---\n",
      "roles-based-on-skills.csv loaded successfully!\n",
      "Number of samples: 4576\n",
      "\n",
      "First 3 rows of roles_skills_df after renaming:\n",
      "   Unnamed: 0           Job Role  \\\n",
      "0           0  Software Engineer   \n",
      "1           1  Software Engineer   \n",
      "2           2  Software Engineer   \n",
      "\n",
      "                                                 ALL  \n",
      "0  Java Android Development PHP HTML C Cascading ...  \n",
      "1                                                ...  \n",
      "2  JavaScript Reactjs MySQL ObjectOriented Progra...  \n",
      "--------------------------------------------------\n",
      "--- Loading Mehyaar/Annotated_NER_PDF_Resumes (PDFs) ---\n",
      "Found 5035 PDF files in ../data/mehyaar_resumes_pdf/. Extracting text...\n",
      "Limiting to first 50 PDFs for faster loading during exploration.\n",
      "Extracted text from 50 Mehyaar PDF resumes.\n",
      "\n",
      "First row of Mehyaar PDFs extracted text (first 500 chars):\n",
      "One97 Communications Limited \n",
      "Data Scientist Jan 2019 to Till Date \n",
      "Detect important information from images and redact\n",
      "required fields. YOLO CNN Object-detection, OCR\n",
      "Insights, find anomaly or performance drop in all\n",
      "possible sub-space. \n",
      "Predict the Insurance claim probability. Estimate the\n",
      "premium amount to be charged\n",
      "B.Tech(Computer Science) from SGBAU university in\n",
      "2017. \n",
      "M.Tech (Computer Science Engineering) from Indian\n",
      "Institute of Technology (IIT), Kanpur in 2019\n",
      "WORK EXPERIENCE\n",
      "EDUCATION...\n",
      "--------------------------------------------------\n",
      "--- Loading spacy_training_data (train.spacy and dev.spacy) ---\n",
      "Loaded 71 training docs from train.spacy\n",
      "Loaded 18 development docs from dev.spacy\n",
      "\n",
      "First document from train.spacy (text and entities):\n",
      "Text: how would you like to join a successful and growing multibillion dollar bank with branches in new jersey and eastern pennsylvania provident bank is looking for a talented banking center supervisor to ...\n",
      "Entities:\n",
      "  - high school diploma or ged (EDUCATIONAL_REQUIREMENTS)\n",
      "--------------------------------------------------\n",
      "--- Loading Job Matcher Data (cnamuangtoun/resume-job-description-fit alternative) ---\n",
      "Job Matcher data (train.csv and test.csv) loaded successfully!\n",
      "Train samples: 6241, Test samples: 1759\n",
      "\n",
      "First 3 rows of Job Matcher training data:\n",
      "                                         resume_text  \\\n",
      "0  SummaryHighly motivated Sales Associate with e...   \n",
      "1  Professional SummaryCurrently working with Cat...   \n",
      "2  SummaryI started my construction career in Jun...   \n",
      "\n",
      "                                job_description_text   label  \n",
      "0  Net2Source Inc. is an award-winning total work...  No Fit  \n",
      "1  At Salas OBrien we tell our clients that were ...  No Fit  \n",
      "2  Schweitzer Engineering Laboratories (SEL) Infr...  No Fit  \n",
      "\n",
      "Columns in Job Matcher training data:\n",
      "['resume_text', 'job_description_text', 'label']\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Job Role Classification Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RESUME-ANALYSER-PROJECT\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Role Classification Model training complete!\n",
      "Accuracy: 0.8908\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "         Business Analyst       0.93      0.96      0.94        98\n",
      "           Cyber Security       0.97      0.91      0.94        78\n",
      "            Data Engineer       0.78      0.57      0.66        54\n",
      "             Data Science       0.86      0.83      0.85        84\n",
      "                   DevOps       0.93      0.90      0.92        94\n",
      "Machine Learning Engineer       0.80      0.82      0.81        97\n",
      "     Mobile App Developer       0.96      0.95      0.95        78\n",
      "         Network Engineer       0.88      0.93      0.91        98\n",
      "        Quality Assurance       0.98      0.95      0.96       101\n",
      "        Software Engineer       0.82      0.93      0.87       134\n",
      "\n",
      "                 accuracy                           0.89       916\n",
      "                macro avg       0.89      0.88      0.88       916\n",
      "             weighted avg       0.89      0.89      0.89       916\n",
      "\n",
      "Job Role Classifier Model and Vectorizer saved.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Placeholder for NER Model Training (Next Major Step) ---\n",
      "Data for spaCy NER training is loaded. Next, you would train a custom NER model using spaCy's training pipeline.\n",
      "This involves creating a spaCy config file, and running `python -m spacy train config.cfg --output ../backend/models/ner_model --paths.train ../data/spacy_training_data/train.spacy --paths.dev ../data/spacy_training_data/dev.spacy`\n",
      "You might also process 'mehyaar_pdfs_df' further to generate more NER training data if its raw PDFs come with corresponding annotations.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Placeholder for Job Matcher Model Training (Next Major Step) ---\n",
      "Data for Job Matcher model training (cnamuangtoun) is loaded.\n",
      "This typically involves:\n",
      "1. Preprocessing 'resume_text' and 'job_description' columns from 'job_match_train_df' and 'job_match_test_df'.\n",
      "2. Engineering features (e.g., embeddings from pre-trained models like BERT/RoBERTa using the 'transformers' library).\n",
      "3. Defining a target variable for 'fit' (e.g., if there's a 'score' or 'match_label' column).\n",
      "4. Training a classification or regression model to predict job fit (e.g., a Siamese network, or simple classifier on concatenated embeddings).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- All initial data analysis and foundational training setup complete. ---\n",
      "You are now ready to dive into detailed NER and Job Matcher model development!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import joblib # For saving models\n",
    "import os # For path manipulation\n",
    "import fitz # PyMuPDF for PDF extraction\n",
    "import docx2txt # For DOCX extraction (though not directly used for Mehyaar PDFs, good to have)\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from datasets import load_dataset # For loading Hugging Face datasets\n",
    "\n",
    "# Ensure spaCy model is downloaded (if not already)\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy 'en_core_web_sm' model...\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# --- 0. Verify Current Working Directory ---\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Utility Functions for Text Extraction ---\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        text = docx2txt.process(docx_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading DOCX {docx_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "# --- 1. Load and Inspect master_resumes.jsonl ---\n",
    "print(\"--- Loading master_resumes.jsonl ---\")\n",
    "master_resumes_df = pd.DataFrame() # Initialize empty DataFrame\n",
    "try:\n",
    "    resumes_data = []\n",
    "    # MODIFIED PATH: Using ../data/ to go up one level then into data/\n",
    "    with open('../data/master_resumes.jsonl', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            resumes_data.append(json.loads(line))\n",
    "    master_resumes_df = pd.DataFrame(resumes_data)\n",
    "    print(\"master_resumes.jsonl loaded successfully!\")\n",
    "    print(f\"Number of samples: {len(master_resumes_df)}\")\n",
    "    print(\"\\nFirst 3 rows of master_resumes_df:\")\n",
    "    print(master_resumes_df.head(3))\n",
    "    print(\"-\" * 50)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: '../data/master_resumes.jsonl' not found. Please check path and file existence.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading master_resumes.jsonl: {e}\")\n",
    "\n",
    "# --- 2. Load and Inspect training_data.csv ---\n",
    "print(\"--- Loading training_data.csv (for Job Description analysis) ---\")\n",
    "training_data_df = pd.DataFrame()\n",
    "try:\n",
    "    # MODIFIED PATH\n",
    "    training_data_df = pd.read_csv('../data/training_data.csv')\n",
    "    print(\"training_data.csv loaded successfully!\")\n",
    "    print(f\"Number of samples: {len(training_data_df)}\")\n",
    "    print(\"\\nFirst 3 rows of training_data_df:\")\n",
    "    print(training_data_df.head(3))\n",
    "    print(\"-\" * 50)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: '../data/training_data.csv' not found. Please check path and file existence.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading training_data.csv: {e}\")\n",
    "\n",
    "\n",
    "# --- 3. Load and Inspect roles-based-on-skills.csv ---\n",
    "print(\"--- Loading roles-based-on-skills.csv (for Job Role Classification) ---\")\n",
    "roles_skills_df = pd.DataFrame()\n",
    "try:\n",
    "    # MODIFIED PATH\n",
    "    roles_skills_df = pd.read_csv('../data/roles-based-on-skills.csv')\n",
    "    print(\"roles-based-on-skills.csv loaded successfully!\")\n",
    "    roles_skills_df.rename(columns={'Target': 'Job Role'}, inplace=True)\n",
    "    print(f\"Number of samples: {len(roles_skills_df)}\")\n",
    "    print(\"\\nFirst 3 rows of roles_skills_df after renaming:\")\n",
    "    print(roles_skills_df.head(3))\n",
    "    print(\"-\" * 50)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: '../data/roles-based-on-skills.csv' not found. Please check path and file existence.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading roles-based-on-skills.csv: {e}\")\n",
    "\n",
    "\n",
    "# --- 4. Load Mehyaar/Annotated_NER_PDF_Resumes (Downloaded PDF files) ---\n",
    "print(\"--- Loading Mehyaar/Annotated_NER_PDF_Resumes (PDFs) ---\")\n",
    "# MODIFIED PATH: Relative to notebooks/\n",
    "mehyaar_pdf_dir = '../data/mehyaar_resumes_pdf/'\n",
    "mehyaar_extracted_data = []\n",
    "\n",
    "if os.path.exists(mehyaar_pdf_dir) and os.listdir(mehyaar_pdf_dir):\n",
    "    pdf_files = [f for f in os.listdir(mehyaar_pdf_dir) if f.lower().endswith('.pdf')]\n",
    "    print(f\"Found {len(pdf_files)} PDF files in {mehyaar_pdf_dir}. Extracting text...\")\n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        if i >= 50: # Limit processing for initial exploration to 50 files for faster loading\n",
    "            print(\"Limiting to first 50 PDFs for faster loading during exploration.\")\n",
    "            break\n",
    "        pdf_path = os.path.join(mehyaar_pdf_dir, pdf_file)\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        mehyaar_extracted_data.append({\"filename\": pdf_file, \"text\": text})\n",
    "\n",
    "    mehyaar_pdfs_df = pd.DataFrame(mehyaar_extracted_data)\n",
    "    print(f\"Extracted text from {len(mehyaar_pdfs_df)} Mehyaar PDF resumes.\")\n",
    "    print(\"\\nFirst row of Mehyaar PDFs extracted text (first 500 chars):\")\n",
    "    if not mehyaar_pdfs_df.empty:\n",
    "        print(mehyaar_pdfs_df.iloc[0]['text'][:500] + \"...\")\n",
    "    print(\"-\" * 50)\n",
    "else:\n",
    "    print(f\"Error: '{mehyaar_pdf_dir}' not found or empty. Please ensure Mehyaar PDF resumes are placed there.\")\n",
    "\n",
    "\n",
    "# --- 5. Load spacy_training_data (for custom NER training) ---\n",
    "print(\"--- Loading spacy_training_data (train.spacy and dev.spacy) ---\")\n",
    "# MODIFIED PATHS\n",
    "train_spacy_path = '../data/spacy_training_data/train.spacy'\n",
    "dev_spacy_path = '../data/spacy_training_data/dev.spacy'\n",
    "\n",
    "train_docs = None\n",
    "dev_docs = None\n",
    "\n",
    "if os.path.exists(train_spacy_path) and os.path.exists(dev_spacy_path):\n",
    "    try:\n",
    "        # Load DocBin files\n",
    "        doc_bin = DocBin().from_disk(train_spacy_path)\n",
    "        train_docs = list(doc_bin.get_docs(nlp.vocab)) # Use your loaded nlp vocab\n",
    "        print(f\"Loaded {len(train_docs)} training docs from train.spacy\")\n",
    "\n",
    "        doc_bin = DocBin().from_disk(dev_spacy_path)\n",
    "        dev_docs = list(doc_bin.get_docs(nlp.vocab)) # Use your loaded nlp vocab\n",
    "        print(f\"Loaded {len(dev_docs)} development docs from dev.spacy\")\n",
    "\n",
    "        print(\"\\nFirst document from train.spacy (text and entities):\")\n",
    "        if train_docs:\n",
    "            sample_doc = train_docs[0]\n",
    "            print(f\"Text: {sample_doc.text[:200]}...\")\n",
    "            print(\"Entities:\")\n",
    "            for ent in sample_doc.ents:\n",
    "                print(f\"  - {ent.text} ({ent.label_})\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading spaCy DocBin files: {e}\")\n",
    "        print(\"Please ensure 'train.spacy' and 'dev.spacy' are valid spaCy DocBin files.\")\n",
    "else:\n",
    "    print(f\"Error: '{train_spacy_path}' or '{dev_spacy_path}' not found. Please ensure spaCy training data is placed there.\")\n",
    "\n",
    "\n",
    "# --- 6. Load Job Matcher Data (cnamuangtoun/resume-job-description-fit alternative) ---\n",
    "print(\"--- Loading Job Matcher Data (cnamuangtoun/resume-job-description-fit alternative) ---\")\n",
    "# MODIFIED PATHS\n",
    "job_match_train_csv_path = '../data/job_match_data/train.csv' # Adjust if file names are different\n",
    "job_match_test_csv_path = '../data/job_match_data/test.csv' # Adjust if file names are different\n",
    "\n",
    "job_match_train_df = pd.DataFrame()\n",
    "job_match_test_df = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(job_match_train_csv_path) and os.path.exists(job_match_test_csv_path):\n",
    "    try:\n",
    "        job_match_train_df = pd.read_csv(job_match_train_csv_path)\n",
    "        job_match_test_df = pd.read_csv(job_match_test_csv_path)\n",
    "        print(\"Job Matcher data (train.csv and test.csv) loaded successfully!\")\n",
    "        print(f\"Train samples: {len(job_match_train_df)}, Test samples: {len(job_match_test_df)}\")\n",
    "        print(\"\\nFirst 3 rows of Job Matcher training data:\")\n",
    "        print(job_match_train_df.head(3))\n",
    "        print(\"\\nColumns in Job Matcher training data:\")\n",
    "        print(job_match_train_df.columns.tolist())\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Job Matcher CSV files: {e}\")\n",
    "else:\n",
    "    print(f\"Error: '{job_match_train_csv_path}' or '{job_match_test_csv_path}' not found.\")\n",
    "    print(\"Please ensure 'cnamuangtoun/resume-job-description-fit' (train.csv, test.csv) are downloaded and placed in 'data/job_match_data/'.\")\n",
    "\n",
    "\n",
    "# --- Job Role Classification Model Training (Existing Logic, remains the same) ---\n",
    "if not roles_skills_df.empty:\n",
    "    print(\"\\n--- Training Job Role Classification Model ---\")\n",
    "    X = roles_skills_df['ALL']\n",
    "    y = roles_skills_df['Job Role']\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Job Role Classification Model training complete!\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    models_dir = '../backend/models' # MODIFIED PATH\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    joblib.dump(tfidf_vectorizer, os.path.join(models_dir, 'tfidf_vectorizer.joblib'))\n",
    "    joblib.dump(model, os.path.join(models_dir, 'job_role_classifier_model.joblib'))\n",
    "    print(\"Job Role Classifier Model and Vectorizer saved.\")\n",
    "    print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"\\nSkipping Job Role Classification: 'roles-based-on-skills.csv' not loaded or empty.\")\n",
    "\n",
    "\n",
    "# --- Placeholder for NER Model Training (Next Major Step) ---\n",
    "print(\"\\n--- Placeholder for NER Model Training (Next Major Step) ---\")\n",
    "if train_docs and dev_docs:\n",
    "    print(\"Data for spaCy NER training is loaded. Next, you would train a custom NER model using spaCy's training pipeline.\")\n",
    "    print(\"This involves creating a spaCy config file, and running `python -m spacy train config.cfg --output ../backend/models/ner_model --paths.train ../data/spacy_training_data/train.spacy --paths.dev ../data/spacy_training_data/dev.spacy`\") # MODIFIED PATHS in command\n",
    "    print(\"You might also process 'mehyaar_pdfs_df' further to generate more NER training data if its raw PDFs come with corresponding annotations.\")\n",
    "else:\n",
    "    print(\"Skipping NER Model Training placeholder: spaCy training data not fully loaded.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- Placeholder for Job Matcher Model Training ---\n",
    "print(\"\\n--- Placeholder for Job Matcher Model Training (Next Major Step) ---\")\n",
    "if not job_match_train_df.empty and not job_match_test_df.empty:\n",
    "    print(\"Data for Job Matcher model training (cnamuangtoun) is loaded.\")\n",
    "    print(\"This typically involves:\")\n",
    "    print(\"1. Preprocessing 'resume_text' and 'job_description' columns from 'job_match_train_df' and 'job_match_test_df'.\")\n",
    "    print(\"2. Engineering features (e.g., embeddings from pre-trained models like BERT/RoBERTa using the 'transformers' library).\")\n",
    "    print(\"3. Defining a target variable for 'fit' (e.g., if there's a 'score' or 'match_label' column).\")\n",
    "    print(\"4. Training a classification or regression model to predict job fit (e.g., a Siamese network, or simple classifier on concatenated embeddings).\")\n",
    "else:\n",
    "    print(\"Skipping Job Matcher Model Training placeholder: Job Matcher dataset not fully loaded.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "print(\"\\n--- All initial data analysis and foundational training setup complete. ---\")\n",
    "print(\"You are now ready to dive into detailed NER and Job Matcher model development!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0c818f-58c5-4376-add7-13f40e19651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\RESUME-ANALYSER-PROJECT\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os; print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2849a-9a39-4d56-a137-06b041f24814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Resume Analyzer Project (venv)",
   "language": "python",
   "name": "resumeanalyzerenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
